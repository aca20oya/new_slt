2024-04-19 08:02:28,588 Hello! This is Joey-NMT.
2024-04-19 08:02:28,591 Total params: 75118260
2024-04-19 08:02:29,257 cfg.name                           : dgs_experiment
2024-04-19 08:02:29,257 cfg.data.data_path                 : ./data/
2024-04-19 08:02:29,257 cfg.data.version                   : dgs_corpus
2024-04-19 08:02:29,257 cfg.data.sgn                       : sign
2024-04-19 08:02:29,257 cfg.data.txt                       : text
2024-04-19 08:02:29,257 cfg.data.gls                       : gloss
2024-04-19 08:02:29,257 cfg.data.train                     : dgs_train
2024-04-19 08:02:29,257 cfg.data.dev                       : dgs_dev
2024-04-19 08:02:29,258 cfg.data.test                      : dgs_test
2024-04-19 08:02:29,258 cfg.data.feature_size              : 274
2024-04-19 08:02:29,258 cfg.data.level                     : word
2024-04-19 08:02:29,258 cfg.data.txt_lowercase             : True
2024-04-19 08:02:29,258 cfg.data.max_sent_length           : 400
2024-04-19 08:02:29,258 cfg.data.random_train_subset       : -1
2024-04-19 08:02:29,258 cfg.data.random_dev_subset         : -1
2024-04-19 08:02:29,258 cfg.data.gls_vocab                 : ./data/gls.vocab
2024-04-19 08:02:29,258 cfg.data.txt_vocab                 : ./data/txt.vocab
2024-04-19 08:02:29,259 cfg.data.batch_size                : 2
2024-04-19 08:02:29,259 cfg.testing.translation_beam_sizes : [1]
2024-04-19 08:02:29,259 cfg.testing.translation_beam_alphas : [0]
2024-04-19 08:02:29,259 cfg.training.reset_best_ckpt       : True
2024-04-19 08:02:29,259 cfg.training.reset_scheduler       : True
2024-04-19 08:02:29,259 cfg.training.reset_optimizer       : True
2024-04-19 08:02:29,259 cfg.training.random_seed           : 44
2024-04-19 08:02:29,259 cfg.training.model_dir             : ./SavedModels/example22
2024-04-19 08:02:29,259 cfg.training.recognition_loss_weight : 0
2024-04-19 08:02:29,260 cfg.training.translation_loss_weight : 1.0
2024-04-19 08:02:29,260 cfg.training.kl_weight             : 1
2024-04-19 08:02:29,260 cfg.training.eval_metric           : bleu
2024-04-19 08:02:29,260 cfg.training.optimizer             : adam
2024-04-19 08:02:29,260 cfg.training.learning_rate         : 0.001
2024-04-19 08:02:29,260 cfg.training.batch_size            : 2
2024-04-19 08:02:29,260 cfg.training.eval_batch_size       : 2
2024-04-19 08:02:29,260 cfg.training.num_valid_log         : 5
2024-04-19 08:02:29,260 cfg.training.epochs                : 1
2024-04-19 08:02:29,261 cfg.training.early_stopping_metric : eval_metric
2024-04-19 08:02:29,261 cfg.training.batch_type            : sentence
2024-04-19 08:02:29,261 cfg.training.translation_normalization : batch
2024-04-19 08:02:29,261 cfg.training.eval_recognition_beam_size : 1
2024-04-19 08:02:29,261 cfg.training.eval_translation_beam_size : 1
2024-04-19 08:02:29,261 cfg.training.eval_translation_beam_alpha : 0
2024-04-19 08:02:29,261 cfg.training.overwrite             : True
2024-04-19 08:02:29,261 cfg.training.shuffle               : True
2024-04-19 08:02:29,261 cfg.training.use_cuda              : True
2024-04-19 08:02:29,262 cfg.training.translation_max_output_length : 30
2024-04-19 08:02:29,262 cfg.training.keep_last_ckpts       : 1
2024-04-19 08:02:29,262 cfg.training.batch_multiplier      : 1
2024-04-19 08:02:29,262 cfg.training.logging_freq          : 20
2024-04-19 08:02:29,262 cfg.training.validation_freq       : 100
2024-04-19 08:02:29,262 cfg.training.betas                 : [0.9, 0.998]
2024-04-19 08:02:29,262 cfg.training.scheduling            : plateau
2024-04-19 08:02:29,262 cfg.training.learning_rate_min     : 1e-05
2024-04-19 08:02:29,262 cfg.training.patience              : 6
2024-04-19 08:02:29,262 cfg.training.decrease_factor       : 0.8
2024-04-19 08:02:29,263 cfg.training.label_smoothing       : 0.0
2024-04-19 08:02:29,263 cfg.model.gloss_input              : False
2024-04-19 08:02:29,263 cfg.model.initializer              : xavier
2024-04-19 08:02:29,263 cfg.model.bias_initializer         : zeros
2024-04-19 08:02:29,263 cfg.model.init_gain                : 1.0
2024-04-19 08:02:29,263 cfg.model.embed_initializer        : xavier
2024-04-19 08:02:29,263 cfg.model.embed_init_gain          : 1.0
2024-04-19 08:02:29,263 cfg.model.tied_softmax             : False
2024-04-19 08:02:29,263 cfg.model.simplified_inference     : True
2024-04-19 08:02:29,264 cfg.model.inference_sample_size    : 4
2024-04-19 08:02:29,264 cfg.model.encoder.skip_encoder     : False
2024-04-19 08:02:29,264 cfg.model.encoder.type             : transformer
2024-04-19 08:02:29,264 cfg.model.encoder.bayesian_attention : True
2024-04-19 08:02:29,264 cfg.model.encoder.bayesian_feedforward : True
2024-04-19 08:02:29,264 cfg.model.encoder.ibp              : False
2024-04-19 08:02:29,264 cfg.model.encoder.activation       : lwta
2024-04-19 08:02:29,264 cfg.model.encoder.lwta_competitors : 4
2024-04-19 08:02:29,264 cfg.model.encoder.num_layers       : 2
2024-04-19 08:02:29,265 cfg.model.encoder.num_heads        : 8
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.embedding_dim : 512
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.scale : False
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.bayesian : True
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.ibp   : False
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.dropout : 0.2
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.norm_type : batch
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.activation_type : lwta
2024-04-19 08:02:29,265 cfg.model.encoder.embeddings.lwta_competitors : 4
2024-04-19 08:02:29,266 cfg.model.encoder.hidden_size      : 512
2024-04-19 08:02:29,266 cfg.model.encoder.ff_size          : 2048
2024-04-19 08:02:29,266 cfg.model.encoder.dropout          : 0.2
2024-04-19 08:02:29,266 cfg.model.decoder.type             : transformer
2024-04-19 08:02:29,266 cfg.model.decoder.num_layers       : 2
2024-04-19 08:02:29,266 cfg.model.decoder.num_heads        : 8
2024-04-19 08:02:29,266 cfg.model.decoder.bayesian_attention : True
2024-04-19 08:02:29,266 cfg.model.decoder.bayesian_feedforward : True
2024-04-19 08:02:29,266 cfg.model.decoder.bayesian_output  : True
2024-04-19 08:02:29,266 cfg.model.decoder.ibp              : False
2024-04-19 08:02:29,267 cfg.model.decoder.activation       : lwta
2024-04-19 08:02:29,267 cfg.model.decoder.lwta_competitors : 4
2024-04-19 08:02:29,267 cfg.model.decoder.embeddings.embedding_dim : 512
2024-04-19 08:02:29,267 cfg.model.decoder.embeddings.scale : False
2024-04-19 08:02:29,267 cfg.model.decoder.embeddings.bayesian : False
2024-04-19 08:02:29,267 cfg.model.decoder.embeddings.dropout : 0.2
2024-04-19 08:02:29,267 cfg.model.decoder.embeddings.norm_type : batch
2024-04-19 08:02:29,267 cfg.model.decoder.hidden_size      : 512
2024-04-19 08:02:29,267 cfg.model.decoder.ff_size          : 2048
2024-04-19 08:02:29,268 cfg.model.decoder.dropout          : 0.2
2024-04-19 08:02:29,268 Data set sizes: 
	train 50507,
	valid 6313,
	test 6314
2024-04-19 08:02:29,268 First training example:
	[GLS] NONE
	[TXT] as his favorite daughter she used to be with her father all the time.
2024-04-19 08:02:29,268 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) NONE
2024-04-19 08:02:29,268 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) i (6) to (7) and (8) a (9) was
2024-04-19 08:02:29,268 Number of unique glosses (types): 4
2024-04-19 08:02:29,269 Number of unique words (types): 29530
2024-04-19 08:02:29,269 SignModel(
	encoder=TransformerEncoder(num_layers=2, num_heads=8),
	decoder=TransformerDecoder(num_layers=2, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=274),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=29530))
2024-04-19 08:02:29,279 EPOCH 1
