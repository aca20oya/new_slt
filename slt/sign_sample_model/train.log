2024-04-18 12:59:44,464 Hello! This is Joey-NMT.
2024-04-18 12:59:44,468 Total params: 56884158
2024-04-18 12:59:44,468 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2024-04-18 12:59:52,950 cfg.name                           : sign_experiment
2024-04-18 12:59:52,950 cfg.data.data_path                 : ./data/
2024-04-18 12:59:52,951 cfg.data.version                   : dgs_corpus
2024-04-18 12:59:52,951 cfg.data.sgn                       : sign
2024-04-18 12:59:52,951 cfg.data.txt                       : text
2024-04-18 12:59:52,951 cfg.data.gls                       : gloss
2024-04-18 12:59:52,951 cfg.data.train                     : dgs_train
2024-04-18 12:59:52,951 cfg.data.dev                       : dgs_dev
2024-04-18 12:59:52,951 cfg.data.test                      : dgs_test
2024-04-18 12:59:52,951 cfg.data.feature_size              : 274
2024-04-18 12:59:52,951 cfg.data.level                     : word
2024-04-18 12:59:52,952 cfg.data.txt_lowercase             : True
2024-04-18 12:59:52,952 cfg.data.max_sent_length           : 400
2024-04-18 12:59:52,952 cfg.data.random_train_subset       : -1
2024-04-18 12:59:52,952 cfg.data.random_dev_subset         : -1
2024-04-18 12:59:52,952 cfg.data.gls_vocab                 : sign_sample_model/gls.vocab
2024-04-18 12:59:52,952 cfg.data.txt_vocab                 : sign_sample_model/txt.vocab
2024-04-18 12:59:52,952 cfg.testing.recognition_beam_sizes : [1]
2024-04-18 12:59:52,952 cfg.testing.translation_beam_sizes : [1]
2024-04-18 12:59:52,952 cfg.testing.translation_beam_alphas : [0]
2024-04-18 12:59:52,953 cfg.training.reset_best_ckpt       : False
2024-04-18 12:59:52,953 cfg.training.reset_scheduler       : False
2024-04-18 12:59:52,953 cfg.training.reset_optimizer       : False
2024-04-18 12:59:52,953 cfg.training.random_seed           : 42
2024-04-18 12:59:52,953 cfg.training.model_dir             : ./sign_sample_model
2024-04-18 12:59:52,953 cfg.training.recognition_loss_weight : 1.0
2024-04-18 12:59:52,953 cfg.training.translation_loss_weight : 1.0
2024-04-18 12:59:52,953 cfg.training.eval_metric           : bleu
2024-04-18 12:59:52,953 cfg.training.optimizer             : adam
2024-04-18 12:59:52,954 cfg.training.learning_rate         : 0.001
2024-04-18 12:59:52,954 cfg.training.batch_size            : 32
2024-04-18 12:59:52,954 cfg.training.num_valid_log         : 5
2024-04-18 12:59:52,954 cfg.training.epochs                : 10
2024-04-18 12:59:52,954 cfg.training.early_stopping_metric : eval_metric
2024-04-18 12:59:52,954 cfg.training.batch_type            : sentence
2024-04-18 12:59:52,954 cfg.training.translation_normalization : batch
2024-04-18 12:59:52,954 cfg.training.eval_recognition_beam_size : 1
2024-04-18 12:59:52,954 cfg.training.eval_translation_beam_size : 1
2024-04-18 12:59:52,955 cfg.training.eval_translation_beam_alpha : -1
2024-04-18 12:59:52,955 cfg.training.overwrite             : True
2024-04-18 12:59:52,955 cfg.training.shuffle               : True
2024-04-18 12:59:52,955 cfg.training.use_cuda              : True
2024-04-18 12:59:52,955 cfg.training.translation_max_output_length : 30
2024-04-18 12:59:52,955 cfg.training.keep_last_ckpts       : 1
2024-04-18 12:59:52,955 cfg.training.batch_multiplier      : 1
2024-04-18 12:59:52,955 cfg.training.logging_freq          : 100
2024-04-18 12:59:52,955 cfg.training.validation_freq       : 1000
2024-04-18 12:59:52,956 cfg.training.betas                 : [0.9, 0.998]
2024-04-18 12:59:52,956 cfg.training.scheduling            : plateau
2024-04-18 12:59:52,956 cfg.training.learning_rate_min     : 1e-07
2024-04-18 12:59:52,956 cfg.training.weight_decay          : 0.001
2024-04-18 12:59:52,956 cfg.training.patience              : 8
2024-04-18 12:59:52,956 cfg.training.decrease_factor       : 0.7
2024-04-18 12:59:52,956 cfg.training.label_smoothing       : 0.0
2024-04-18 12:59:52,956 cfg.model.initializer              : xavier
2024-04-18 12:59:52,956 cfg.model.bias_initializer         : zeros
2024-04-18 12:59:52,957 cfg.model.init_gain                : 1.0
2024-04-18 12:59:52,957 cfg.model.embed_initializer        : xavier
2024-04-18 12:59:52,957 cfg.model.embed_init_gain          : 1.0
2024-04-18 12:59:52,957 cfg.model.tied_softmax             : False
2024-04-18 12:59:52,957 cfg.model.encoder.type             : transformer
2024-04-18 12:59:52,957 cfg.model.encoder.num_layers       : 3
2024-04-18 12:59:52,957 cfg.model.encoder.num_heads        : 8
2024-04-18 12:59:52,957 cfg.model.encoder.embeddings.embedding_dim : 512
2024-04-18 12:59:52,957 cfg.model.encoder.embeddings.scale : False
2024-04-18 12:59:52,958 cfg.model.encoder.embeddings.dropout : 0.1
2024-04-18 12:59:52,958 cfg.model.encoder.embeddings.norm_type : batch
2024-04-18 12:59:52,958 cfg.model.encoder.embeddings.activation_type : softsign
2024-04-18 12:59:52,958 cfg.model.encoder.hidden_size      : 512
2024-04-18 12:59:52,958 cfg.model.encoder.ff_size          : 2048
2024-04-18 12:59:52,958 cfg.model.encoder.dropout          : 0.1
2024-04-18 12:59:52,958 cfg.model.decoder.type             : transformer
2024-04-18 12:59:52,958 cfg.model.decoder.num_layers       : 3
2024-04-18 12:59:52,958 cfg.model.decoder.num_heads        : 8
2024-04-18 12:59:52,959 cfg.model.decoder.embeddings.embedding_dim : 512
2024-04-18 12:59:52,959 cfg.model.decoder.embeddings.scale : False
2024-04-18 12:59:52,959 cfg.model.decoder.embeddings.dropout : 0.1
2024-04-18 12:59:52,959 cfg.model.decoder.embeddings.norm_type : batch
2024-04-18 12:59:52,959 cfg.model.decoder.embeddings.activation_type : softsign
2024-04-18 12:59:52,959 cfg.model.decoder.hidden_size      : 512
2024-04-18 12:59:52,959 cfg.model.decoder.ff_size          : 2048
2024-04-18 12:59:52,959 cfg.model.decoder.dropout          : 0.1
2024-04-18 12:59:52,959 Data set sizes: 
	train 50507,
	valid 6313,
	test 6314
2024-04-18 12:59:52,960 First training example:
	[GLS] TAUB-GEHÃ–RLOS1 HIN1 URLAUB8 $INDEX1
	[TXT] a deaf person traveled to israel.
2024-04-18 12:59:52,960 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) $INDEX1 (4) ICH1 (5) ICH2 (6) $PROD (7) $GEST (8) DU1 (9) $GEST-ABWINKEN1
2024-04-18 12:59:52,960 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) i (6) to (7) and (8) a (9) was
2024-04-18 12:59:52,960 Number of unique glosses (types): 8638
2024-04-18 12:59:52,960 Number of unique words (types): 29530
2024-04-18 12:59:52,960 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=274),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=29530))
2024-04-18 12:59:52,979 EPOCH 1
2024-04-18 13:00:03,321 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   7.615376 => Gls Tokens per Sec:     1601 || Batch Translation Loss:  33.547424 => Txt Tokens per Sec:     3072 || Lr: 0.001000
2024-04-18 13:00:09,042 [Epoch: 001 Step: 00000200] Batch Recognition Loss:   7.587710 => Gls Tokens per Sec:     2923 || Batch Translation Loss:  34.607449 => Txt Tokens per Sec:     5639 || Lr: 0.001000
2024-04-18 13:00:14,834 [Epoch: 001 Step: 00000300] Batch Recognition Loss:   7.568852 => Gls Tokens per Sec:     2893 || Batch Translation Loss:  67.503471 => Txt Tokens per Sec:     5516 || Lr: 0.001000
2024-04-18 13:00:20,608 [Epoch: 001 Step: 00000400] Batch Recognition Loss:   7.819754 => Gls Tokens per Sec:     2838 || Batch Translation Loss:  40.867641 => Txt Tokens per Sec:     5493 || Lr: 0.001000
2024-04-18 13:00:26,314 [Epoch: 001 Step: 00000500] Batch Recognition Loss:   7.781006 => Gls Tokens per Sec:     2855 || Batch Translation Loss:  53.853889 => Txt Tokens per Sec:     5546 || Lr: 0.001000
2024-04-18 13:00:32,040 [Epoch: 001 Step: 00000600] Batch Recognition Loss:   7.683286 => Gls Tokens per Sec:     2914 || Batch Translation Loss:  42.864449 => Txt Tokens per Sec:     5537 || Lr: 0.001000
2024-04-18 13:00:37,781 [Epoch: 001 Step: 00000700] Batch Recognition Loss:   7.750127 => Gls Tokens per Sec:     2854 || Batch Translation Loss:  72.035767 => Txt Tokens per Sec:     5471 || Lr: 0.001000
2024-04-18 13:00:43,476 [Epoch: 001 Step: 00000800] Batch Recognition Loss:   7.273448 => Gls Tokens per Sec:     2848 || Batch Translation Loss:  68.927834 => Txt Tokens per Sec:     5524 || Lr: 0.001000
2024-04-18 13:00:49,264 [Epoch: 001 Step: 00000900] Batch Recognition Loss:   7.993935 => Gls Tokens per Sec:     2807 || Batch Translation Loss:  44.108448 => Txt Tokens per Sec:     5478 || Lr: 0.001000
2024-04-18 13:00:55,091 [Epoch: 001 Step: 00001000] Batch Recognition Loss:   8.079492 => Gls Tokens per Sec:     2867 || Batch Translation Loss:  28.550293 => Txt Tokens per Sec:     5463 || Lr: 0.001000
2024-04-18 13:30:23,271 Hooray! New best validation result [eval_metric]!
2024-04-18 13:30:23,271 Saving new checkpoint.
